{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28d99d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman India\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "training_loss:0.0091,0.7711\n",
      "validation_loss:0.0042,0.8878\n",
      "training_loss:0.0038,0.8932\n",
      "validation_loss:0.0033,0.9061\n",
      "training_loss:0.0032,0.9070\n",
      "validation_loss:0.0029,0.9145\n",
      "training_loss:0.0029,0.9165\n",
      "validation_loss:0.0027,0.9236\n",
      "training_loss:0.0026,0.9238\n",
      "validation_loss:0.0024,0.9301\n",
      "training_loss:0.0024,0.9300\n",
      "validation_loss:0.0023,0.9331\n",
      "training_loss:0.0022,0.9363\n",
      "validation_loss:0.0021,0.9383\n",
      "training_loss:0.0020,0.9409\n",
      "validation_loss:0.0020,0.9429\n",
      "training_loss:0.0019,0.9452\n",
      "validation_loss:0.0019,0.9447\n",
      "training_loss:0.0018,0.9485\n",
      "validation_loss:0.0018,0.9475\n",
      "training_loss:0.0016,0.9518\n",
      "validation_loss:0.0017,0.9490\n",
      "training_loss:0.0015,0.9549\n",
      "validation_loss:0.0016,0.9528\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "#it is a pytorch library\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "#its for data visualization\n",
    "\n",
    "\n",
    "import numpy as np  \n",
    "# MAthematical Calculation\n",
    "\n",
    "import torch.nn.functional as func  \n",
    "\n",
    "\n",
    "import PIL.ImageOps  \n",
    "\n",
    "#dealing with Images\n",
    "\n",
    "from torch import nn  \n",
    "#nn is a special package in pytorch that deals with neural networks\n",
    "\n",
    "from torchvision import datasets,transforms   \n",
    "#We need some to train our neural network and for thsat we have to iport from some where and torch vision is for the same\n",
    "\n",
    "\n",
    "import requests  \n",
    "#for url fetching\n",
    "\n",
    "from PIL import Image  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform1=transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])  \n",
    "\n",
    "training_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform1)  \n",
    "\n",
    "#validation_dataset=datasets.MNIST(root='./data',train=False,download=True,transform=transform1)  \n",
    "\n",
    "training_loader=torch.utils.data.DataLoader(dataset=training_dataset,batch_size=100,shuffle=True) \n",
    "\n",
    "validation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=100,shuffle=False) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def im_convert(tensor):  \n",
    "    image=tensor.clone().detach().numpy()  \n",
    "    image=image.transpose(1,2,0)  \n",
    "    print(image.shape)  \n",
    "    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  \n",
    "    image=image.clip(0,1)  \n",
    "    return image  \n",
    "\n",
    "\n",
    "\n",
    "dataiter=iter(training_loader)  \n",
    "images,labels=dataiter.next()  \n",
    "fig=plt.figure(figsize=(25,4))  \n",
    "\n",
    "\n",
    "for idx in np.arange(20):  \n",
    "    ax=fig.add_subplot(2,10,idx+1)  \n",
    "    plt.imshow(im_convert(images[idx]))  \n",
    "    ax.set_title([labels[idx].item()])  \n",
    "    \n",
    "#building the engine  Defining the layers of neural network\n",
    "class classification1(nn.Module):  \n",
    "    \n",
    "    def __init__(self,input_layer,hidden_layer1,hidden_layer2,output_layer):  \n",
    "        super().__init__()  \n",
    "        self.linear1=nn.Linear(input_layer,hidden_layer1)  \n",
    "        self.linear2=nn.Linear(hidden_layer1,hidden_layer2)  \n",
    "        self.linear3=nn.Linear(hidden_layer2,output_layer)  \n",
    "  \n",
    "        \n",
    "    def forward(self,x):  \n",
    "        x=func.relu(self.linear1(x))  \n",
    "        x=func.relu(self.linear2(x))  \n",
    "        x=self.linear3(x)  \n",
    "        return x  \n",
    "    \n",
    "#defining the parametrs   \n",
    "model=classification1(784,125,65,10)  \n",
    "\n",
    "#loss function\n",
    "criteron=nn.CrossEntropyLoss()  \n",
    "\n",
    "#optimization algorithm\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001)  \n",
    "\n",
    "\n",
    "\n",
    "epochs=12  \n",
    "\n",
    "loss_history=[]  \n",
    "\n",
    "correct_history=[]  \n",
    "\n",
    "\n",
    "val_loss_history=[]  \n",
    "val_correct_history=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for e in range(epochs):  \n",
    "    loss=0.0  \n",
    "    correct=0.0  \n",
    "    val_loss=0.0  \n",
    "    val_correct=0.0  \n",
    "\n",
    "    \n",
    "    for input,labels in training_loader:  \n",
    "        inputs=input.view(input.shape[0],-1)  \n",
    "        outputs=model(inputs)  \n",
    "        loss1=criteron(outputs,labels)  \n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        loss1.backward() \n",
    "        \n",
    "        optimizer.step()  \n",
    "        _,preds=torch.max(outputs,1)  \n",
    "        loss+=loss1.item()  \n",
    "        correct+=torch.sum(preds==labels.data)  \n",
    "        \n",
    "    else:  \n",
    "        with torch.no_grad():  \n",
    "            for val_input,val_labels in validation_loader:  \n",
    "                val_inputs=val_input.view(val_input.shape[0],-1)  \n",
    "                val_outputs=model(val_inputs)  \n",
    "                val_loss1=criteron(val_outputs,val_labels)   \n",
    "                _,val_preds=torch.max(val_outputs,1)  \n",
    "                val_loss+=val_loss1.item()  \n",
    "                val_correct+=torch.sum(val_preds==val_labels.data)  \n",
    "                \n",
    "                \n",
    "        epoch_loss=loss/len(training_loader.dataset)  \n",
    "        epoch_acc=correct.float()/len(training_dataset)  \n",
    "        loss_history.append(epoch_loss)  \n",
    "        correct_history.append(epoch_acc)  \n",
    "          \n",
    "        val_epoch_loss=val_loss/len(validation_loader.dataset)  \n",
    "        val_epoch_acc=val_correct.float()/len(validation_dataset)  \n",
    "        val_loss_history.append(val_epoch_loss)  \n",
    "        val_correct_history.append(val_epoch_acc)  \n",
    "        print('training_loss:{:.4f},{:.4f}'.format(epoch_loss,epoch_acc.item()))  \n",
    "        print('validation_loss:{:.4f},{:.4f}'.format(val_epoch_loss,val_epoch_acc.item()))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "132b8e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "url='https://i.stack.imgur.com/CF1ze.jpg'\n",
    "response=requests.get(url,stream=True)  \n",
    "img=Image.open(response.raw)  \n",
    "img=PIL.ImageOps.invert(img)  \n",
    "img=img.convert('1')  \n",
    "img=transform1(img)   \n",
    "plt.imshow(im_convert(img))  \n",
    "\n",
    "img=img.view(img.shape[0],-1)  \n",
    "output=model(img)  \n",
    "_,pred=torch.max(output,1)  \n",
    "print(pred.item())  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bbeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
